# @title
import xml.etree.ElementTree as ET
import pandas as pd
import re
from datetime import date, timedelta

# --------------------------------------------------------------------------
# ğŸŒŸ ë§ˆìŠ¤í‚¹ ë¬¸ì ì„¤ì •: ' ' (ê³µë°±) ë˜ëŠ” '_' (ì–¸ë”ë°”) ì¤‘ ì„ íƒí•˜ì„¸ìš”.
MASKING_CHAR = '_'
# --------------------------------------------------------------------------

def get_target_dates_id_list(start_date, end_date):
    """
    íƒœì¡° 2ë…„ 3ì›” 1ì¼ë¶€í„° 7ì›” 31ì¼ê¹Œì§€ì˜ 7ìë¦¬ ID (YYMMDDD, ì˜ˆ: '0204001') ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    date_id_list = set()
    current_date = start_date
    while current_date < end_date:
        sillok_date_id = f"02{current_date.month:02d}{current_date.day:03d}"
        date_id_list.add(sillok_date_id)
        current_date += timedelta(days=1)
    return date_id_list

# --------------------------------------------------------------------------
# 2. XML íŒŒì¼ íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
# --------------------------------------------------------------------------

def parse_xml_for_sillok_data(file_path, target_date_ids, masking_char):
    extracted_data = []

    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        print(f"âœ… íŒŒì¼ ë¡œë“œ ì„±ê³µ: {file_path}")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {file_path}")
        return []
    except ET.ParseError:
        print(f"âŒ ì˜¤ë¥˜: XML íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ êµ¬ì¡°ê°€ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {file_path}")
        return []

    print("\n--- ë‚ ì§œ í•„í„°ë§ ë° í…ìŠ¤íŠ¸ ë§ˆìŠ¤í‚¹ ì§„í–‰ ì¤‘ ---")

    for article in root.findall('.//level5'):
        article_id = article.get('id')

        if not article_id or len(article_id) < 12:
            continue

        date_id_seven_digits = article_id[5:12]

        # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
        if date_id_seven_digits in target_date_ids:

            # 3. ê¸°ì‚¬ ì œëª© ì¶”ì¶œ
            title_element = article.find('./front/biblioData/title/mainTitle')
            title = title_element.text.strip() if title_element is not None and title_element.text else "ì œëª© ì—†ìŒ"

            # 4. í•œë¬¸ ì›ë¬¸ ì¶”ì¶œ ë° ë§ˆìŠ¤í‚¹
            paragraph_element = article.find('./text/content/paragraph')
            chinese_text = ""

            if paragraph_element is not None:
                raw_text = ET.tostring(paragraph_element, encoding='unicode')

                # ğŸŒŸğŸŒŸğŸŒŸ ìˆ˜ì •ëœ ë§ˆìŠ¤í‚¹ ë¡œì§ ğŸŒŸğŸŒŸğŸŒŸ

                # <index...> íƒœê·¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš©(í•œì í¬í•¨) ì „ì²´ë¥¼ ë§ˆìŠ¤í‚¹ ë¬¸ìë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
                # (flags=re.DOTALL: . ë¬¸ìê°€ ê°œí–‰ë¬¸ì(\n)ë„ í¬í•¨í•˜ë„ë¡ ì„¤ì •)
                cleaned_text = re.sub(r'<index[^>]*>.*?</index>', masking_char, raw_text, flags=re.DOTALL)

                # <annotation> íƒœê·¸ ë° ë‚´ìš© ì œê±° (ì´ì „ê³¼ ë™ì¼)
                cleaned_text = re.sub(r'<annotation[^>]*>.*?</annotation>', '', cleaned_text, flags=re.DOTALL)

                # <paragraph> íƒœê·¸ ìì²´ ì œê±° ë° ë‚˜ë¨¸ì§€ ì •ë¦¬ (ì´ì „ê³¼ ë™ì¼)
                cleaned_text = re.sub(r'<paragraph[^>]*>|.*?:/|</paragraph>', '', cleaned_text)
                cleaned_text = re.sub(r'&lt;.*?&gt;', '', cleaned_text)

                # ì—¬ëŸ¬ ê°œì˜ ê³µë°±/ì–¸ë”ë°”ê°€ ì—°ì†ë  ê²½ìš° í•˜ë‚˜ë¡œ í•©ì¹˜ê³  ì •ë¦¬
                chinese_text = re.sub(r'\s+', ' ', cleaned_text).strip()
                chinese_text = re.sub(f'{re.escape(masking_char)}+', masking_char, chinese_text).strip()

            # 5. ê²°ê³¼ ì €ì¥ (IDì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ë‹¤ì‹œ ì¶”ì¶œ)
            year_part = int(article_id[5:7])
            month_part = int(article_id[7:9])
            day_part = int(article_id[9:12])

            extracted_data.append({
                "ID": article_id,
                "ë°œí–‰ì¼": f"íƒœì¡° {year_part}ë…„ {month_part}ì›” {day_part}ì¼",
                "ê¸°ì‚¬ì œëª©": title,
                "ë³¸ë¬¸ë‚´ìš©_í•œë¬¸_ì›ë¬¸_ë§ˆìŠ¤í‚¹": chinese_text
            })

    return extracted_data

# --------------------------------------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# --------------------------------------------------------------------------

# 1. ëŒ€ìƒ ê¸°ê°„ ì„¤ì •
START_DATE = date(1393, 3, 1)
EXCLUSIVE_END_DATE = date(1393, 8, 1)

target_dates_list = get_target_dates_id_list(START_DATE, EXCLUSIVE_END_DATE)
XML_FILES_TO_PROCESS = ['2nd_waa_102.xml']

print(f"â­ ì¶”ì¶œ ëŒ€ìƒ ê¸°ê°„: íƒœì¡° 2ë…„ 3ì›” 1ì¼ë¶€í„° 7ì›” 31ì¼ ({len(target_dates_list)}ì¼)")

final_results = []
for file in XML_FILES_TO_PROCESS:
    # ğŸŒŸ ë§ˆìŠ¤í‚¹ ë¬¸ì ì „ë‹¬ ğŸŒŸ
    results = parse_xml_for_sillok_data(file, set(target_dates_list), MASKING_CHAR)
    final_results.extend(results)

if final_results:
    df_final = pd.DataFrame(final_results)

    df_final.drop_duplicates(subset=['ID'], inplace=True)
    df_final.sort_values(by='ID', inplace=True)

    output_filename = 'a020701_í•œë¬¸ì›ë¬¸_ìµœì¢…ë§ˆìŠ¤í‚¹_.tsv'
    df_final.to_csv(output_filename, index=False, encoding='utf-8-sig', sep='\t', quoting=1)

    print("\n" + "="*50)
    print(f"ğŸ‰ ì´ {len(df_final)}ê°œì˜ ê¸°ì‚¬(í•œë¬¸ ì›ë¬¸) ì¶”ì¶œ ë° ì €ì¥ ì™„ë£Œ! (ë§ˆìŠ¤í‚¹ ë¬¸ì: {MASKING_CHAR})")
    print(f"**ê²°ê³¼ íŒŒì¼ëª…: {output_filename}**")
    print("="*50)

    display(df_final.head())

else:
    print("\nìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ íŒŒì¼ ë‚´ì— ì§€ì •ëœ ê¸°ê°„ì˜ ê¸°ì‚¬ê°€ ì—†ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
